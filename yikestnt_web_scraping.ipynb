{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4135f14",
   "metadata": {},
   "source": [
    "# Background of this research\n",
    "\n",
    "Before getting into scraping, I need to determine which website I am going to scrape from. Earlier on I discovered that I had to do some experimentation on HOW to scrape, because there are different ways and they don't all work the same on different websites/brands.\n",
    "\n",
    "Ranking of Jewelry Brands:\n",
    "1. Van Cleef and Arpels 1906 ; 505.7M USD\n",
    "    - https://www.vancleefarpels.com/us/en/the-maison/timeline/origins.html#:~:text=Born%20in%20the%20wake%20of,debut%20of%20a%20bejeweled%20destiny.\n",
    "    - https://www.zoominfo.com/c/van-cleef--arpels/170328141\n",
    "2. Cartier 1847 ; 6.2B\n",
    "    - https://www.cartier.com/en-sk/maison/the-story/story-and-heritage\n",
    "    - https://www.zippia.com/cartier-careers-18270/revenue/#\n",
    "3. CatbirdNYC 2004 ; 60.2M USD\n",
    "    - https://www.brooklynnavyyard.org/tenants/catbird/\n",
    "    - https://growjo.com/company/Catbird_NYC#google_vignette\n",
    "4. Laurie Fleming Jewelry approx. 2014\n",
    "    - https://www.appmybizaccount.gov.on.ca/onbis/businessnames/viewInstance/view.pub?id=185e6c856f92f2744af3ee5b87a9ed2f11e4b9fc2c846b7587cb497c8c3736b9&_timestamp=4631642856566348\n",
    "    \n",
    "**Table 1: Jewelry brands and what methods can be used to scrape from them**\n",
    "\n",
    "|Company|Basic Request| Selenium| Proxy| Web Scraping Service|\n",
    "|:-----:|:-----------:|:-------:|:----:|:-------------------:|\n",
    "|CatbirdNYC| No          | Yes       | x    | x              |\n",
    "|Cartier| No          | x       | x    | x                   |\n",
    "|Van Cleef and Arpels| No          | Yes       | x    | x                   |\n",
    "|Laurie Fleming | Yes          | x       | x    | x              |\n",
    "    \n",
    "In terms of VCA versus Cartier ranking, VCA is known as more of an upscale brand for jewelry than Cartier because it is pricier and handmade.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e82a673",
   "metadata": {},
   "source": [
    "# Intended Audience and Audience Background\n",
    "\n",
    "Anyone is welcome to read through my \"research\"! It's for fun and for anyone who shares my interest (or even if they don't)! It's not extremely technical or thorough, to be clear, since I did some basic research and I did not cite sources for the most part. \n",
    "\n",
    "If any reader's would like to use this code, they need some technical background and basic coding ability. This code and task does not go into deeper topics like memory allocation, but knowledge on coding, scraping, website security, html, javascript, and more, will make it easier to understand (not that what I'm doing is terribly difficult). \n",
    "\n",
    "# Research Process\n",
    "\n",
    "Before delving into the code, here is the outline of this notebook. To preface, I haven't scraped websites before besides using Reddit API years ago, so I don't have much knowledge or experience in these regards.\n",
    "\n",
    "Check a websites robots.txt file before/during this process to have a better idea of what websites do or do not allow.\n",
    "\n",
    "I am testing/trying to scrape from mainly Van Cleef and Arpels. I started with the basic requests library, and realized that didn't work on all jewelry websites, probably to prevent scraping from bots or scalpers. \n",
    "\n",
    "Based on the table above, in Table 1, you can see that the basic request only works on Laurie Fleming Jewelry's website and CatbirdNYC's website. It does not work on Van Cleef and Arpels, nor Cartier. I think the reason why is because higher end luxury companies have more resources for extra features like preventative measures on their websites, and these companies in particular have more incentive to protect against resellers/scalpers since their items are in hot demand and are worth a lot. \n",
    "\n",
    "When I couldn't scrape from VCA, I used Selenium. \n",
    "\n",
    "Selenium capabilities:\n",
    "-  can interact with web pages the same way a real user would, including dynamically generated content from JavaScript\n",
    "- allows you to perform actions on web elements such as clicking buttons, filling out forms, or scrolling\n",
    "- can handle client-side validations, pop-ups, alerts, and cookies in real-time, replicating a user's session more accurately\n",
    "\n",
    "The last point, was what I noticed was causing issues in the regular requests. My header information, particularly the cookies, was not correct or perhaps had session specific data that while executing it with the regular requests, caused issues and I could not retrieve the HTML data.\n",
    "\n",
    "# How You Can Use This Code\n",
    "\n",
    "My logic flow:\n",
    "\n",
    "1. Get the website/page that has \"out of stock\" for the item you want\n",
    "2. Add the link into the selenium code portion\n",
    "3. Add email alerts (?) for restock notifications\n",
    "4. Add your code with your specifications to a shell script to execute continuously \n",
    "\n",
    "I added code at the bottom that could be used to email yourself an alert when an item comes. I also added the simple shell script code that you would put this python code into.\n",
    "\n",
    "# Questions\n",
    "\n",
    "1. Can I cause issues by submitting a bunch of requests? Does that give me information on rate limits?\n",
    "2. Can I get in trouble and/or banned for scraping?\n",
    "3. What kind of capabilites are scraping APIs offering? Are they used by bots and scalpers? How useful is it for the tasks?\n",
    "\n",
    "# Conclusion and Future Work\n",
    "\n",
    "I learned that Selenium is an absolute must for scraping. I also don't know how these companies deal with bots, and I would not want them to block my IP, so I would also implement proxies to rotate my IPs. If I were to perform these searches on a larger scale, for example for multiple people wanting this information or on multiple items, I would look into using an API, both for the learning experience and for the convenience. I would also use a Google Chrome driver instead of a Safari driver, because it would be easier for the email notification portion. The reason why I didn't is because downgrading Google Chrome is difficult, and I didn't know how to downgrade it to match the driver (the latest version was newer than the newest driver).\n",
    "\n",
    "If I continued this project, I would like to create a website for ease of use, that one could input some basic information and then sign up for alerts on restocks. That would require me to at a minimum:\n",
    "- Pay for a scraping API service\n",
    "- Create a website\n",
    "- Implement a backend database for emails of users\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3154a23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.safari.service import Service as SafariService\n",
    "\n",
    "import requests\n",
    "import os\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b07a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Request code\n",
    "# def main():\n",
    "#     url = \"https://www.vancleefarpels.com/us/en/collections/jewelry/alhambra/vcara45900---vintage-alhambra-pendant.html\"\n",
    "    \n",
    "#     response = requests.get(url)\n",
    "    \n",
    "#     soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "#     #elements = soup.find_all(class_=\"comment\")\n",
    "    \n",
    "#     print(f\"Elements: {len(elements)}\")\n",
    "#     print(f\"Scraping: {url}\")\n",
    "#     #print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5d78234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I made the driver Safari because I couldn't downgrade chrome to match the current driver\n",
    "driver = webdriver.Safari()\n",
    "driver.get(url)\n",
    "\n",
    "# Get page source and parse with BeautifulSoup\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "page_source = driver.page_source\n",
    "#print(page_source)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdba8111",
   "metadata": {},
   "source": [
    "# CatbirdNYC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9d70a8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = 'https://laurieflemingjewellery.com/products/hidden-fairy-charm'\n",
    "#url = 'https://www.cartier.com/en-us/jewelry/rings/love/love-ring-CRB4084600.html'\n",
    "# url = 'https://www.catbirdnyc.com/jewelry/collections/city-exclusive-charms.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7c899fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_you_want = 'Cherry Blossom Gold Charm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "53f196ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    elements = soup.find_all('li', class_=\"item product product-item\")\n",
    "    product_cards = soup.find_all('product-card')\n",
    "    \n",
    "    print(f\"Elements Found: {len(elements)}\")\n",
    "    for i, element in enumerate(elements):\n",
    "        #print(f\"Element {i + 1}:\")\n",
    "        #print(\"Raw HTML:\")\n",
    "        #print(element.prettify())  # Pretty-print HTML for better readability\n",
    "\n",
    "        name_tag = element.find('a', class_='product-item-link') # finds name of item \n",
    "        \n",
    "        name = name_tag.text.strip() if name_tag else 'No name found'\n",
    "        if name == item_you_want:\n",
    "            sold_out = product_cards[i].get('data-is-sold-out')\n",
    "            if (sold_out) == \"1\":\n",
    "                print(\"it is sold out\")\n",
    "        # Comment the following code below back in if you want your computer to alert you\n",
    "#         else:\n",
    "#             os.system('say \"Hi, your item is in stock.\"')\n",
    "            price_tag = element.find('span', class_='price')\n",
    "            price = price_tag.text.strip() if price_tag else 'No price found'\n",
    "\n",
    "            print(f\"Product Name: {name}\")\n",
    "            print(f\"Price: {price}\")\n",
    "            print('-' * 40)\n",
    "\n",
    "    print(f\"Scraping: {url}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04d66ea",
   "metadata": {},
   "source": [
    "# VCA section\n",
    "\n",
    "\n",
    "I tried by inspecting the web page, seeing what information is sent from my computer to VCA, and inputing that information manually in my request header but it didn't work. I think the cookie information was important, but maybe session specific information didn't match. In any case, when I removed the cookie information, it was an immediate access denied, but with, my script was spinning around and attempting the request.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b2b708",
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = \"https://www.vancleefarpels.com/us/en/collections/jewelry/alhambra/vcara45900---vintage-alhambra-pendant.html\"\n",
    "#VCA w/o stock\n",
    "# url = 'https://www.vancleefarpels.com/us/en/collections/jewelry/alhambra/vcard34900---vintage-alhambra-pendant.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8fa61695",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\",\n",
    "    \"accept-encoding\": \"gzip, deflate, br, zstd\",\n",
    "    \"accept-language\": \"en-US,en;q=0.9\",\n",
    "    \"cache-control\": \"max-age=0\",\n",
    "    \"sec-ch-ua\": '\"Not/A)Brand\";v=\"99\", \"Google Chrome\";v=\"115\", \"Chromium\";v=\"115\"',\n",
    "    \"sec-ch-ua-mobile\": \"?0\",\n",
    "    \"sec-ch-ua-platform\": \"Windows\",\n",
    "    \"sec-fetch-dest\": \"document\",\n",
    "    \"sec-fetch-mode\": \"navigate\",\n",
    "    \"sec-fetch-site\": \"none\",\n",
    "    \"sec-fetch-user\": \"?1\",\n",
    "    \"upgrade-insecure-requests\": \"1\",\n",
    "    \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5b2401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, VCA alhambra necklace\n",
    "# Need to specify the material and gold color\n",
    "# Available example\n",
    "item_you_want = 'Vintage Alhambra pendant'\n",
    "material_type = '18K yellow gold, Mother-of-pearl'\n",
    "\n",
    "# Not available example\n",
    "# item_you_want = 'Vintage Alhambra pendant'\n",
    "# material_type = '18K white gold, Chalcedony'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862e9815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    elements = soup.find_all('main', class_=\"vca-main\")\n",
    "    \n",
    "    print(f\"Elements Found: {len(elements)}\")\n",
    "    for i, element in enumerate(elements):\n",
    "#         print(f\"Element {i + 1}:\")\n",
    "#         print(\"Raw HTML:\")\n",
    "#         print(element.prettify())  # Pretty-print HTML for better readability\n",
    "\n",
    "        #name_tag = element.find('a', class_='product-item-link') # finds name of item \n",
    "        \n",
    "        #name = name_tag.text.strip() if name_tag else 'No name found'\n",
    "        availability = element.find('section',class_='vca-product vca-product-v1 vca-component')\n",
    "        #print(availability)\n",
    "        if availability:\n",
    "            data_tracking = availability.get('data-tracking')\n",
    "            #print(data_tracking)\n",
    "            json_data_tracking = json.loads(data_tracking)\n",
    "            name = json_data_tracking[0].get('item_name')\n",
    "            price = json_data_tracking[0].get('price')\n",
    "            \n",
    "            item_sellable = json_data_tracking[0].get('item_sellable')\n",
    "            \n",
    "            if item_sellable == 'true':\n",
    "                print(\"Item is available\")\n",
    "                os.system('say \"Hi, your item is in stock.\"')\n",
    "            else:\n",
    "                print(\"Item is not available\")\n",
    "\n",
    "            print(f\"Product Name: {name}\")\n",
    "            print(f\"Price: {price}\")\n",
    "            print('-' * 40)\n",
    "\n",
    "    print(f\"Scraping: {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "fa4a470f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elements Found: 13\n",
      "it is sold out\n",
      "Product Name: Cherry Blossom Gold Charm\n",
      "Price: $144.00\n",
      "----------------------------------------\n",
      "Scraping: https://www.catbirdnyc.com/jewelry/collections/city-exclusive-charms.html\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcb727c",
   "metadata": {},
   "source": [
    "# Email alerts\n",
    "\n",
    "You have to do some extra configuration if you want to email yourself. You can go into your gmail account settings to figure it out. I didn't add it because it was annoying and I don't want to add my email in here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9e2b16e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "364f5c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to send email: [Errno 61] Connection refused\n"
     ]
    }
   ],
   "source": [
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "\n",
    "# Open a plain text file for reading. For this example, assume that\n",
    "# the text file contains only ASCII characters.\n",
    "textfile = 'textfile.txt'\n",
    "with open(textfile, 'r', encoding='utf-8') as fp:\n",
    "    # Create a text/plain message\n",
    "    msg = MIMEText(fp.read(), 'plain', 'utf-8')\n",
    "\n",
    "# Sender and recipient email addresses\n",
    "me = \"xxx@gmail.com\"\n",
    "you = \"xxx@gmail.com\"\n",
    "\n",
    "# Create the email headers\n",
    "msg['Subject'] = f'The contents of {textfile}'\n",
    "msg['From'] = me\n",
    "msg['To'] = you\n",
    "\n",
    "# Send the message via our SMTP server\n",
    "try:\n",
    "    with smtplib.SMTP('localhost') as s:\n",
    "        s.sendmail(me, [you], msg.as_string())\n",
    "    print('Email sent successfully!')\n",
    "except Exception as e:\n",
    "    print(f'Failed to send email: {e}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
